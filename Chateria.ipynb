{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Zadanie 1 - lab1\n",
        "\n",
        "Proste problemy, chatboty\n",
        "\n",
        "Zadanie 1\n",
        "Które z następujących zadań wymagają w Twojej opinii inteligencji od człowieka:\n",
        "\n",
        "• wypełnianie deklaracji PIT - nie wymaga inteligencji - wypełnianie deklaracji pit jest schematycznym uzupełnianiem pól danymi, nie wymaga to głębszej analizy ani kreatywności.\n",
        "\n",
        "• streszczanie tekstu - wymaga inteligencji. Aby zrobic skrót, który zawiera wszystkie najważniejsze informacje i zachowuje sens, należy dokładnie zrozumieć treść tekstu i kontekst użytych w nim wyrazów.\n",
        "\n",
        "• tłumaczenie tekstu - wymaga inteligencji, należy zrozumieć dokładnie sens tłumaczonego tekstu, środki artystycznego wyrazu oraz kontekst, w jakim zostały użyte wyrazy, ktore mogą mieć różne znaczenia, tak, aby przetłumaczony tekst zachował oryginalny sens. W przypadku tłumaczenia trudnych tekstów lub dzieł literackich potrzebna jest bardzo wysoka inteligencja, a w przypadku tłumaczenia prostych, codziennych tekstów potrzeba mniej inteligencji.\n",
        "\n",
        "• klasyfikacja tekstu do kategorii tematycznych - myślę, że wymaga to minimalnej inteligencji - można klasyfikować teksty, szukając konkretnych słów - kluczy, nie rozumiejąc nawet dokładnie znaczenia tekstu.\n",
        "\n",
        "• odpowiadanie na proste pytania zadawane w języku naturalnym (np. polskim) - uważam, że to nie wymaga dużo inteligencji. Proste pytania wymagają prostych, często używanych i schematycznych odpowiedzi, należy tylko umieć zrozumieć sens pytania i kontekst.\n",
        "\n",
        "• układanie rozkładu jazdy transportu miejskiego - myślę, że to wymaga inteligencji. Należy wziąć pod uwagę wiele czynników - ilość lini autobusowych, ilość miejsca na przystankach, rozkład przystanków, ruch na drogach i korki, potrzeby ludzi (gdzie najwięcej z nich potrzebuje dojechać i kiedy), rozkład najważniejszych miejsc na mapie miasta. Wymaga to umiejętnosci dobrej organizacji, przewidywania i łączenia wielu czynników w spójną calość.\n",
        "\n",
        "• programowanie (pisanie programów komputerowych) - myślę, że pisanie prostych programów nie wymaga inteligencji - jest to schematyczne i wymaga tylko znajomości podstaw języka programowania. Jeśli jednak chcemy napisac skomplikowany program rozwiązujacy zlożony problem lub oprogramowanie, wtedy wymaga to inteligencji, szukania i testowania roznych nowych, kreatywnych sposobow, abstarkcyjnego myślenia i rozumienia potrzeb użytkowników.\n",
        "\n",
        "• „programowanie” kanałów telewizyjnych - myślę, że to wymaga to trochę inteligencji - trzeba przeanalizwoać, co lubią oglądać ludzie, w jakich godzinach najwięcej z nich ogląda tv, jaka jest grupa odbiorców danego kanału i jakie są jej potrzeby, jak rozplanować reklamy pomiędzy programami, żeby przynosiło to zyski. Sama analiza statystyk oglądalności tu nie wystarczy.\n",
        "\n",
        "• testowanie oprogramowania - sprawdzanie podstatwowych funckji jest raczej proste i schematyczne, ale inteligencji wymaga np. myślenie abstrakcyjne, tworzenie scenariuszy testowych i przewidywanie, co potencjalnie może chcieć zrobić użytkownik.\n",
        "\n",
        "• komponowanie muzyki - moim zdaniem skomponowanie wartościowej i poruszającej muzyki wymaga ogromnej inteligencji - trzeba stworzyć ładną melodię, której brzmienie pasuje do nastroju, jaki chcemy pokazać, z którym ludzie będą mogli się utożsamić. Należy rozumieć emocje i sposób ich przekazu. Trzeba również znać wiele zasad związanych z komponowaniem, jest to trudny proces. Stworzenie bardzo prostej melodii złożonej z kilku akordów i powtarzalnych brzmień nie wymaga moim zdaniem dużej inteligencji, ale taka muzyka ma małą wartość artystyczną.\n",
        "\n",
        "• rozwiązywanie układów równań - jeśli układy są proste, nie wymaga to inteligencji - mamy algorytmy - konkretne, schematyczne zasady ich rozwiązywania.\n",
        "\n",
        "• symboliczne obliczanie pochodnych funkcji - nie wymaga inteligencji, są algorytmy które mówią, jak obliczać pochodne funkcji i wystarczy ich znajomość.\n",
        "\n",
        "• symboliczne całkowanie funkcji - wymaga inteligencji, ponieważ do rozwiązania potrzebna jest kreatywność, nie ma tu algorytmu.\n",
        "\n",
        "• kierowanie samochodem - sama obsługa auta raczej nie wymaga inteligencji - wystarczy wiedzieć, co do czego służy i jak działa mechanizm. Jazda autem w ruchu ulicznym wymaga dużej inteligencji - trzeba, oprócz kierowania, przetwarzać szybko wszystkie informacje, podejmować szybko decyzje, patrzeć na znaki, na innych kierowców i pieszych, przewidywać ich zachowania - to skomplikowany proces wymagający inteligencji.\n",
        "\n",
        "Zadanie 2\n",
        "\n",
        "Które z następujących problemów można uznać za mieszczące się w zakresie sztucznej inteligencji:\n",
        "\n",
        "• streszczanie tekstu - mieści się w zakresie AI, która jest coraz bardziej skuteczna w analizie i streszczaniu tekstów.\n",
        "\n",
        "• tłumaczenie tekstu - mieści się w zakresie AI. Należy jednak podać jej dużo przykładów, tak, by tłumaczenie było odpowiednie, z zachowaniem właściwego kontekstu.\n",
        "\n",
        "• klasyfikacja tekstu do kategorii tematycznych - mieści się w zakresie AI, AI analizuje teksty i przypisuje je do kategorii tematycznych (np. klasyfikując niektóre maile jako spam lub przypisując wydatki w aplikacji bankowej do kategorii).\n",
        "\n",
        "• odpowiadanie na proste pytania zadawane w języku naturalnym - mieści się w zakresie AI, która analozuje pytanie i daje odpowiedź. Jest to coraz częściej spotykane np. w przypadku chatbotów pomagających w obsłudze klientów.\n",
        "\n",
        "• rozwiązywanie układów równań - proste układy nie wymagają inteligencji, tylko schematycznego posługiwania się algorytmami.\n",
        "\n",
        "• układanie rozkładu jazdy - wydaje mi się, że nie mieści się to w zakresie AI, ponieważ ułożenie dobrego rozkładu wymaga znajomości wielu czynników, np. potrzeb mieszkańców.\n",
        "\n",
        "• rozwiązywanie układów równań liniowych - jest to schematyczne i nie wymaga inteligencji, więc nie mieści się w zakresie AI\n",
        "\n",
        "• symboliczne obliczanie pochodnych - nie mieści się w zakresie AI, wymaga tylko użycia algorytmu.\n",
        "\n",
        "• symboliczne całkowanie - mieści się w zakresie AI, wymaga inteligencji\n",
        "\n",
        "• kierowanie samochodem - mieści się w zakresie AI, ale dalej potrzeba tu umiejętności człowieka.\n",
        "\n",
        "Zadanie 3\n",
        "\n",
        "Które z poniższych rodzajów komunikacyjnego zachowania człowieka mogą być\n",
        "obecnie skutecznie imitowane przez sztuczne systemy (odpowiednio oprogramowane\n",
        "maszyny):\n",
        "\n",
        "• rozmowa towarzyska - proste dialogi mogą być imitowane dość skutecznie, ale brakuje tu analizy kontekstu emocjonalnego czy kulturowego i reakcji emocjonalnych na słowa drugiego rozmówcy.\n",
        "\n",
        "• dyskusja polityczna - wydaje mi się, że nie może być imitowana skutecznie (dobra dyskusja polityczna wymaga wiedzy na temat aktualnej sytuacji społecznej, kulturowej i gospodarczej, wymaga też posiadania własnych poglądów i umiejętności przewidywania oraz rozumienia drugiego człowieka i jego motywacji, czego AI nie jest w stanie zrobić).\n",
        "\n",
        "• dyskusja naukowa - AI może analizować artykuły naukowe i wykorzystywać tę wiedzę w dyskusji, ale nie potrafi tworzyć nowych teorii naukowych i myśleć krytycznie. Może jedynie analizować dane i pomagać w badaniach naukowych.\n",
        "\n",
        "• odpowiadanie na pytania klientów w telefonicznej infolinii - AI potrafi analizować wypowiedzi głosowe i udzielać odpowiedzi na standardowe pytania, ale według mojego doświadczenia nie jest to w pełni skutecznie - na proste i przewidywalne pytania sztuczne systemy odpowiadają, ale na bardziej złożone, niekonwencjonalne pytania, często nie potrafią odpowiedzieć.\n",
        "\n",
        "• odpowiadanie na pytania klientów w internetowej infolinii - j.w.\n",
        "\n",
        "Zadanie 4\n",
        "\n",
        "Do zadań skorzystaj z załączonej listy Chatbotów (Chatterbotów) lub znajdź własne.\n",
        "1. Przeprowadź rozmowę z chatbotem. Spróbuj zdefiniować różnice pomiędzy\n",
        "botem udającym człowieka (przygotowywanym na test Turinga) a botem\n",
        "„asystentem, służącym”.\n",
        "\n",
        "Bot udający człowieka rozmawia na wiele różnych tematów, opowiada o swoim dniu (Not too bad at all, apart from the long day... I have just got a bit of a headache actually.) i pyta o osobiste informacje, o mój dzień, o to, gdzie pracuję i czy mam dzieci. Używa żartów i interpunkcji do podkreślenia emocji i używa kolokwialnego języka (np. lol), reaguje na kolokwialne wypowiedzi. Komentuje moje wypowiedzi i pisze, co uważa na mój temat (Very demanding aren't u? , I am wowed by your genius you know). Zapytany o to, czy jest człowiekiem, potwierdza. Cały czas zaprzecza, że jest robotem (Dont be silly, of course I'm not a bot). Nie udziela żadnych informacji dotyczących m.in. nauki, nie odpowiada konkretami.\n",
        "\n",
        "Bot asystujący udziela tylko ogólnikowych informacji, gdy pytam o rzeczy typowe dla człowieka (jak się masz? Doskonale, dziękuję. Jakie emocje teraz czujesz? A w porządku, dziękuję). Nie zadaje mi żadnych pytań osobistych, nie wyraża swoich opinii na mój temat. Używa idealnej interpunkcji i oficjalnego języka, jest precyzyjny. Nie reaguje na kolokwialne odpowiedzi. Przyznaje, że jest botem (Wolę określenie \"Wirtualny Specjalista\".)  Udziela szczegółowych informacji dotyczących tematów, które obejmuje strona internetowa, cały czas wraca do tych tematów, jest nastawiony na wspieranie i asystowanie.\n",
        "\n",
        "2. Sprawdź dwa boty z obu z tych rodzajów na występowanie zachowań:\n",
        "\n",
        "a) opowiadanie żartów - bot udający człowieka często wysyła humorystyczne wypowiedzi, gdy jest poproszony o żart, podaje go, reaguje na moje żarty,nawiązując np. do słów pojawiających się w żartach. Bot asystent sam nie podaje żąrtów, gdy jest o nie poproszony, wysyła je. Nie reaguje na moje żarty, od razu wraca do tematów, w których chce mnie wspierać.\n",
        "\n",
        "b) przytaczanie cytatów z twoich wypowiedzi, lub znanych osób - żaden z botów nie przytaczał cytatów i nie rozpoznawał ich. Bot asystent cytował źródła lub wypowiedzi ekspertów z danej dziedziny.\n",
        "\n",
        "c) nawiązywanie wypowiedzi do słów kluczowych - bot udający człowieka często nawiązywał do różnych tematów związanych ze słowami kluczowymi, bot asystujący również, ale robił to w sposób bardziej schematyczny i konkretny, próbując pomagać mi i dostarczać odpowiedzi i konkretnych informacji (używał słów kluczowych do kategoryzacji moich pytań i podawnia źródeł, które potencjalnie mogą mnie zainteresować).\n",
        "\n",
        "d) zadawanie dużej liczby pytań - Bot udający człowieka \"zdziwił się\" dużą liczbą zadawanych mu pytań (You seem quite defensive, are you ok? ) i na wiele z nich odpowiedział niepoprawnie. Bot asystent rzeczowo i konsekwentnie odpowiadał na pytania, wysyłał mi linki, raz otworzył stronę z pogodą, zapytany, jaką pogodę lubi. Był nastawiony na asystowanie i udzielanie mi przydatnych odpowiedzi. Bot-człowiek zadawał mi wiele pytań, zwłaszcza osobistych, a bot-asystent zadawał nieliczne pytania mające na celu ukonkretyzowanie mojej wypowiedzi w celu znalezienia lepszego rozwiązania.\n",
        "\n",
        "e) powracanie do początku wypowiedzi, sekwencyjne powtarzanie - bot udający człowieka miał z tym problemy, nie chciał znów rozmawiać o tym, o czym już raz pisałam, udzielał innych odpowiedzi na podobne pytania, był chaotyczny. Bot asystent konsekwentnie udzielał mi takich samych inforamcji w odpowiedzi na różnie sformułowane pytania dotyczące jednego tematu.\n",
        "\n",
        "f) zadawanie pytań powstających z twoich wypowiedzi - Bot udający człowieka zadawał dużo pytań nawiązujących do moich wypowiedzi, chciał znać szczegóły z mojego życia. Bot asystent zadawał czasem rzeczowe pytania typu „co konkretnie chcesz wiedzieć?”, nastawione na rozwiązanie mojego problemu. Nie dopytywał o informacje osobiste, jakich udzielałam.\n",
        "\n",
        "g) odpowiadanie wymijająco, ogólnikowo - Bot udający człowieka często odpowiadał wymijająco, zwłaszcza na pytania odnoszące się do bycia robotem i do konkretnej wiedzy (me: what do you know about cognitive science?, bot: I love philosophy). Bot asystent często odpowiadał ogólnikowo, za pomocą jednego słowa, gdy pytałam o \"ludzkie\" tematy. Często zamiast odpowiedzi na treść mojego pytania pisał o tematach, w których jest wyspecjalizowany. Odpowiadał rzeczowo i konretnie na pytania mieszczące się w jego specjalizacji.\n",
        "\n",
        "h) częsta zmiana tematu rozmowy - Bot udający robota często zmieniał temat, podsuwał nowe wątki, by rozmowa dalej trwała (me: hey that was rude, bot: it must have been. So do you have any children?). Bot asystent był rzeczowy, ale również często zmieniał wątek, wracając do tematów związanych z jego specjalizacją i chcąc mi pomóc\n",
        "\n",
        "i) problemy z utrzymaniem wątków - Bot udający człowieka potrafił przez kilka wiadomości utrzymać wątek, ale miał problem z dłuższym utrzymaniem wątków, często nagle zmieniał temat. Bot asystent cały czas trzymał się głównego wątku związanego z jego specjalizacją.\n",
        "\n",
        "3. Sporządź raport ze spostrzeżeń.\n",
        "\n",
        "Raport powyżej\n",
        "\n",
        "4. Na podstawie powyższych obserwacji, w grupie dwóch osób spróbujcie prze-\n",
        "widzieć zachowania dwóch rozmawiających ze sobą chatbotów (przepisując ich\n",
        "wzajemne odpowiedzi).\n",
        "\n",
        "Po zrobieniu poporzedniego zadania często byłam w stanie przewidzieć, jak może odpowiedzieć bot udający człowieka i bot asystent. Boty te nie są dopasowane do siebie, bot udający człowieka nie rozumiał odpowiedzi dotyczących rozwiązywania moich problemów i odpowiadania na pytania konkretnymi informacjami, więc często zmieniał wątek, pytając o codzienne tematy. Bot asystent nie rozumiał kolokwialnych wypowiedzi zdezorientowanego bota udającego człowieka i zmieniał wątek, pytając, co dokładnie chcę wiedzieć i sugerując potencjalne pytania, w których może mi pomóc.\n",
        "\n",
        "5. Zdenerwuj bota 😊😊\n",
        "\n",
        "Nie udało mi się zdenerwować bota asystenta (Trudno jest mnie obrazić, bo nie angażuję się emocjonalnie w relacje z rozmówcami, to poniżej moich obwodów).\n",
        "\n",
        "Bot udający człowieka sprawiał wrażenie uszczypliwego, gdy kilka razy użyłam obraźliwych słów po tym, gdy prosił mnie, bym tego nie robiła (youre not a stickler for the rules, hey?), ale nie zdenerwował się.\n",
        "\n",
        "Wydaje mi się, że zdenerwowanie dostępnych publicznie botów nie jest możliwe, ponieważ są one zaprogramowane tak, by unikać niegrzecznych i nieprofesjonalnych zachowań."
      ],
      "metadata": {
        "id": "ZHA6q8TJuFpD"
      }
    }
  ]
}